{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec7cce29",
   "metadata": {},
   "source": [
    "# This is the notebook for xgboost based classification for Parkinson data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca0f8041",
   "metadata": {},
   "outputs": [],
   "source": [
    "# requirements\n",
    "import os\n",
    "import sys\n",
    "sys.path.insert(0,'..') # to add parent directory\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost\n",
    "from utils.data_loader import PatientsRawData\n",
    "from utils.preprocessing import preprocess_signal\n",
    "from utils.augment_data import get_augmentation_indexes, augment_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "025a1b1d",
   "metadata": {},
   "source": [
    "First let's load the data as they are. Display some data statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4213a7b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Data labels: ['Control', 'Control', 'Control', 'Control', 'Control', 'Control', 'Control', 'Control', 'ET', 'ET', 'ET', 'ET', 'ET', 'ET', 'ET', 'ET', 'ET', 'ET', 'ET', 'ET', 'ET', 'Left', 'Left', 'Left', 'Left', 'Left', 'Left', 'Left', 'Left', 'Left', 'Right', 'Right', 'Right', 'Right', 'Right', 'Right', 'Right', 'Right', 'Right', 'Right', 'Right'] for the total of 41 data samples coming from patients: ['аста0101.txt', 'дюки0102.txt', 'керш0103.txt', 'лега0104.txt', 'сидо0105.txt', 'фрол0106.txt', 'хвал0107.txt', 'черк0108.txt', 'даке0101.txt', 'ершо0102.txt', 'кудр0103.txt', 'купр0104.txt', 'куту0105.txt', 'лити0106.txt', 'луче0107.txt', 'макс0108.txt', 'миро0109.txt', 'молю01010.txt', 'муха01011.txt', 'соко01012.txt', 'тихо01013.txt', 'ерми0101.txt', 'кова0102.txt', 'колг0103.txt', 'медв0104.txt', 'наза0105.txt', 'погр0106.txt', 'савв0107.txt', 'сави0108.txt', 'шелу0109.txt', 'бело0101.txt', 'гава0102.txt', 'голу0103.txt', 'грек0104.txt', 'губа0105.txt', 'павл0106.txt', 'пана0107.txt', 'ротм0108.txt', 'серо0109.txt', 'соло01010.txt', 'хлюс01011.txt']\n",
      "Explore a random data sample: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FP1</th>\n",
       "      <th>FP2</th>\n",
       "      <th>F3</th>\n",
       "      <th>F4</th>\n",
       "      <th>C3</th>\n",
       "      <th>C4</th>\n",
       "      <th>P3</th>\n",
       "      <th>P4</th>\n",
       "      <th>O1</th>\n",
       "      <th>O2</th>\n",
       "      <th>...</th>\n",
       "      <th>F8</th>\n",
       "      <th>T3</th>\n",
       "      <th>T4</th>\n",
       "      <th>T5</th>\n",
       "      <th>T6</th>\n",
       "      <th>CZ</th>\n",
       "      <th>EMG1</th>\n",
       "      <th>EMG2</th>\n",
       "      <th>EMG3</th>\n",
       "      <th>EMG4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>46</td>\n",
       "      <td>3</td>\n",
       "      <td>37</td>\n",
       "      <td>34</td>\n",
       "      <td>9</td>\n",
       "      <td>37</td>\n",
       "      <td>20</td>\n",
       "      <td>9</td>\n",
       "      <td>-17</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>32</td>\n",
       "      <td>61</td>\n",
       "      <td>9</td>\n",
       "      <td>24</td>\n",
       "      <td>-10</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>58</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>-10</td>\n",
       "      <td>25</td>\n",
       "      <td>37</td>\n",
       "      <td>-7</td>\n",
       "      <td>38</td>\n",
       "      <td>14</td>\n",
       "      <td>9</td>\n",
       "      <td>-25</td>\n",
       "      <td>18</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>22</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>-20</td>\n",
       "      <td>1</td>\n",
       "      <td>-32</td>\n",
       "      <td>14</td>\n",
       "      <td>-9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>46</td>\n",
       "      <td>-13</td>\n",
       "      <td>34</td>\n",
       "      <td>52</td>\n",
       "      <td>-6</td>\n",
       "      <td>51</td>\n",
       "      <td>18</td>\n",
       "      <td>16</td>\n",
       "      <td>-33</td>\n",
       "      <td>23</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>27</td>\n",
       "      <td>90</td>\n",
       "      <td>-2</td>\n",
       "      <td>40</td>\n",
       "      <td>-21</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>56</td>\n",
       "      <td>-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>57</td>\n",
       "      <td>-16</td>\n",
       "      <td>41</td>\n",
       "      <td>62</td>\n",
       "      <td>-15</td>\n",
       "      <td>63</td>\n",
       "      <td>23</td>\n",
       "      <td>20</td>\n",
       "      <td>-40</td>\n",
       "      <td>27</td>\n",
       "      <td>...</td>\n",
       "      <td>18</td>\n",
       "      <td>37</td>\n",
       "      <td>109</td>\n",
       "      <td>-6</td>\n",
       "      <td>47</td>\n",
       "      <td>-23</td>\n",
       "      <td>1</td>\n",
       "      <td>-4</td>\n",
       "      <td>31</td>\n",
       "      <td>-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>63</td>\n",
       "      <td>-19</td>\n",
       "      <td>49</td>\n",
       "      <td>63</td>\n",
       "      <td>-12</td>\n",
       "      <td>66</td>\n",
       "      <td>28</td>\n",
       "      <td>20</td>\n",
       "      <td>-42</td>\n",
       "      <td>26</td>\n",
       "      <td>...</td>\n",
       "      <td>19</td>\n",
       "      <td>44</td>\n",
       "      <td>115</td>\n",
       "      <td>-2</td>\n",
       "      <td>50</td>\n",
       "      <td>-27</td>\n",
       "      <td>1</td>\n",
       "      <td>-4</td>\n",
       "      <td>62</td>\n",
       "      <td>-39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   FP1  FP2  F3  F4  C3  C4  P3  P4  O1  O2  ...  F8  T3   T4  T5  T6  CZ  \\\n",
       "0   46    3  37  34   9  37  20   9 -17  14  ...  20  32   61   9  24 -10   \n",
       "1   38  -10  25  37  -7  38  14   9 -25  18  ...  11  22   70   1  31 -20   \n",
       "2   46  -13  34  52  -6  51  18  16 -33  23  ...  12  27   90  -2  40 -21   \n",
       "3   57  -16  41  62 -15  63  23  20 -40  27  ...  18  37  109  -6  47 -23   \n",
       "4   63  -19  49  63 -12  66  28  20 -42  26  ...  19  44  115  -2  50 -27   \n",
       "\n",
       "   EMG1  EMG2  EMG3  EMG4  \n",
       "0     0     6    58     4  \n",
       "1     1   -32    14    -9  \n",
       "2     0     3    56   -25  \n",
       "3     1    -4    31   -30  \n",
       "4     1    -4    62   -39  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = PatientsRawData('../../data/Исходные файлы/')\n",
    "data.load_data()\n",
    "print(f' Data labels: {data.Y} for the total of {len(data.X)} data samples coming from patients: {data.patient}')\n",
    "print('Explore a random data sample: ')\n",
    "N = random.randint(0,len(data.X))\n",
    "data.X[N].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60eaeb08",
   "metadata": {},
   "source": [
    "## Pre-processing\n",
    "Then select only the EMG data and apply pre-processing to the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36da2864",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EMG1</th>\n",
       "      <th>EMG2</th>\n",
       "      <th>EMG3</th>\n",
       "      <th>EMG4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>58</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-32</td>\n",
       "      <td>14</td>\n",
       "      <td>-9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>56</td>\n",
       "      <td>-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>-4</td>\n",
       "      <td>31</td>\n",
       "      <td>-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>-4</td>\n",
       "      <td>62</td>\n",
       "      <td>-39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   EMG1  EMG2  EMG3  EMG4\n",
       "0     0     6    58     4\n",
       "1     1   -32    14    -9\n",
       "2     0     3    56   -25\n",
       "3     1    -4    31   -30\n",
       "4     1    -4    62   -39"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's now clean the data to only have EMG data\n",
    "data.get_emg_data()\n",
    "data.X[N].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db4dd609",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHAPE (67545,)\n",
      "SHAPE (67545,)\n",
      "SHAPE (67545,)\n",
      "SHAPE (67545,)\n",
      "Pre-processed patient 0\n",
      "SHAPE (68835,)\n",
      "SHAPE (68835,)\n",
      "SHAPE (68835,)\n",
      "SHAPE (68835,)\n",
      "Pre-processed patient 1\n",
      "SHAPE (69645,)\n",
      "SHAPE (69645,)\n",
      "SHAPE (69645,)\n",
      "SHAPE (69645,)\n",
      "Pre-processed patient 2\n",
      "SHAPE (66195,)\n",
      "SHAPE (66195,)\n",
      "SHAPE (66195,)\n",
      "SHAPE (66195,)\n",
      "Pre-processed patient 3\n",
      "SHAPE (68325,)\n",
      "SHAPE (68325,)\n",
      "SHAPE (68325,)\n",
      "SHAPE (68325,)\n",
      "Pre-processed patient 4\n",
      "SHAPE (66255,)\n",
      "SHAPE (66255,)\n",
      "SHAPE (66255,)\n",
      "SHAPE (66255,)\n",
      "Pre-processed patient 5\n",
      "SHAPE (68265,)\n",
      "SHAPE (68265,)\n",
      "SHAPE (68265,)\n",
      "SHAPE (68265,)\n",
      "Pre-processed patient 6\n",
      "SHAPE (68265,)\n",
      "SHAPE (68265,)\n",
      "SHAPE (68265,)\n",
      "SHAPE (68265,)\n",
      "Pre-processed patient 7\n",
      "SHAPE (68565,)\n",
      "SHAPE (68565,)\n",
      "SHAPE (68565,)\n",
      "SHAPE (68565,)\n",
      "Pre-processed patient 8\n",
      "SHAPE (68445,)\n",
      "SHAPE (68445,)\n",
      "SHAPE (68445,)\n",
      "SHAPE (68445,)\n",
      "Pre-processed patient 9\n",
      "SHAPE (65490,)\n",
      "SHAPE (65490,)\n",
      "SHAPE (65490,)\n",
      "SHAPE (65490,)\n",
      "Pre-processed patient 10\n",
      "SHAPE (69135,)\n",
      "SHAPE (69135,)\n",
      "SHAPE (69135,)\n",
      "SHAPE (69135,)\n",
      "Pre-processed patient 11\n",
      "SHAPE (70425,)\n",
      "SHAPE (70425,)\n",
      "SHAPE (70425,)\n",
      "SHAPE (70425,)\n",
      "Pre-processed patient 12\n",
      "SHAPE (76395,)\n",
      "SHAPE (76395,)\n",
      "SHAPE (76395,)\n",
      "SHAPE (76395,)\n",
      "Pre-processed patient 13\n",
      "SHAPE (69600,)\n",
      "SHAPE (69600,)\n",
      "SHAPE (69600,)\n",
      "SHAPE (69600,)\n",
      "Pre-processed patient 14\n",
      "SHAPE (67140,)\n",
      "SHAPE (67140,)\n",
      "SHAPE (67140,)\n",
      "SHAPE (67140,)\n",
      "Pre-processed patient 15\n",
      "SHAPE (76576,)\n",
      "SHAPE (76576,)\n",
      "SHAPE (76576,)\n",
      "SHAPE (76576,)\n",
      "Pre-processed patient 16\n",
      "SHAPE (66990,)\n",
      "SHAPE (66990,)\n",
      "SHAPE (66990,)\n",
      "SHAPE (66990,)\n",
      "Pre-processed patient 17\n",
      "SHAPE (69630,)\n",
      "SHAPE (69630,)\n",
      "SHAPE (69630,)\n",
      "SHAPE (69630,)\n",
      "Pre-processed patient 18\n",
      "SHAPE (68640,)\n",
      "SHAPE (68640,)\n",
      "SHAPE (68640,)\n",
      "SHAPE (68640,)\n",
      "Pre-processed patient 19\n",
      "SHAPE (70500,)\n",
      "SHAPE (70500,)\n",
      "SHAPE (70500,)\n",
      "SHAPE (70500,)\n",
      "Pre-processed patient 20\n",
      "SHAPE (66600,)\n",
      "SHAPE (66600,)\n",
      "SHAPE (66600,)\n",
      "SHAPE (66600,)\n",
      "Pre-processed patient 21\n",
      "SHAPE (67185,)\n",
      "SHAPE (67185,)\n",
      "SHAPE (67185,)\n",
      "SHAPE (67185,)\n",
      "Pre-processed patient 22\n",
      "SHAPE (66060,)\n",
      "SHAPE (66060,)\n",
      "SHAPE (66060,)\n",
      "SHAPE (66060,)\n",
      "Pre-processed patient 23\n",
      "SHAPE (65190,)\n",
      "SHAPE (65190,)\n",
      "SHAPE (65190,)\n",
      "SHAPE (65190,)\n",
      "Pre-processed patient 24\n",
      "SHAPE (68160,)\n",
      "SHAPE (68160,)\n",
      "SHAPE (68160,)\n",
      "SHAPE (68160,)\n",
      "Pre-processed patient 25\n",
      "SHAPE (68385,)\n",
      "SHAPE (68385,)\n",
      "SHAPE (68385,)\n",
      "SHAPE (68385,)\n",
      "Pre-processed patient 26\n",
      "SHAPE (67755,)\n",
      "SHAPE (67755,)\n",
      "SHAPE (67755,)\n",
      "SHAPE (67755,)\n",
      "Pre-processed patient 27\n",
      "SHAPE (72150,)\n",
      "SHAPE (72150,)\n",
      "SHAPE (72150,)\n",
      "SHAPE (72150,)\n",
      "Pre-processed patient 28\n",
      "SHAPE (81810,)\n",
      "SHAPE (81810,)\n",
      "SHAPE (81810,)\n",
      "SHAPE (81810,)\n",
      "Pre-processed patient 29\n",
      "SHAPE (65355,)\n",
      "SHAPE (65355,)\n",
      "SHAPE (65355,)\n",
      "SHAPE (65355,)\n",
      "Pre-processed patient 30\n",
      "SHAPE (69795,)\n",
      "SHAPE (69795,)\n",
      "SHAPE (69795,)\n",
      "SHAPE (69795,)\n",
      "Pre-processed patient 31\n",
      "SHAPE (68280,)\n",
      "SHAPE (68280,)\n",
      "SHAPE (68280,)\n",
      "SHAPE (68280,)\n",
      "Pre-processed patient 32\n",
      "SHAPE (65940,)\n",
      "SHAPE (65940,)\n",
      "SHAPE (65940,)\n",
      "SHAPE (65940,)\n",
      "Pre-processed patient 33\n",
      "SHAPE (66735,)\n",
      "SHAPE (66735,)\n",
      "SHAPE (66735,)\n",
      "SHAPE (66735,)\n",
      "Pre-processed patient 34\n",
      "SHAPE (71070,)\n",
      "SHAPE (71070,)\n",
      "SHAPE (71070,)\n",
      "SHAPE (71070,)\n",
      "Pre-processed patient 35\n",
      "SHAPE (71640,)\n",
      "SHAPE (71640,)\n",
      "SHAPE (71640,)\n",
      "SHAPE (71640,)\n",
      "Pre-processed patient 36\n",
      "SHAPE (70860,)\n",
      "SHAPE (70860,)\n",
      "SHAPE (70860,)\n",
      "SHAPE (70860,)\n",
      "Pre-processed patient 37\n",
      "SHAPE (66300,)\n",
      "SHAPE (66300,)\n",
      "SHAPE (66300,)\n",
      "SHAPE (66300,)\n",
      "Pre-processed patient 38\n",
      "SHAPE (67230,)\n",
      "SHAPE (67230,)\n",
      "SHAPE (67230,)\n",
      "SHAPE (67230,)\n",
      "Pre-processed patient 39\n",
      "SHAPE (73800,)\n",
      "SHAPE (73800,)\n",
      "SHAPE (73800,)\n",
      "SHAPE (73800,)\n",
      "Pre-processed patient 40\n"
     ]
    }
   ],
   "source": [
    "# convert data to numpy\n",
    "min_sequence = 10000000000\n",
    "try:\n",
    "    data.convert_to_numpy()\n",
    "except:\n",
    "    print('already converted, skipping!')\n",
    "#preprocess all the data\n",
    "for i in range(len(data.X)):\n",
    "    one_patient_emg = data.X[i]\n",
    "    for j, emg_channel in enumerate(one_patient_emg):\n",
    "        if len(emg_channel)<min_sequence:\n",
    "            min_sequence = len(emg_channel) \n",
    "        processed_signal =  preprocess_signal(emg_channel,  SamplingRate=500,  LF=60, HF=240, frequences_to_filter = [50, 100, 150, 200 ], order_butter=4, save_plot=False) \n",
    "        data.X[i][j]=processed_signal # save to the previous unprocessed signal\n",
    "    print(f'Pre-processed patient {i}')    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d1626f",
   "metadata": {},
   "source": [
    "At this point, we have the processed data. The only problem is that they are not of the same length, so we need to select the smallest lenght of a sequence and cut all the sequences which are longer than this one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6703064d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# min_sequence for the data is 65190, so let's cut everything to this lenght\n",
    "#preprocess all the data\n",
    "for i in range(len(data.X)):\n",
    "    data.X[i]=data.X[i][:,:65190] # save to the previous unprocessed signal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a63a193b",
   "metadata": {},
   "source": [
    "## Dividing into training and validation set\n",
    "The goal of this operation is to have training and validation data sets, which consist from different patients.\n",
    "In the same moment, we want the number of pathologies be the same in training and validation sets.\n",
    "The function is already implemented in the dataset class, so here we just apply it and verify the result.\n",
    "The number of val patients is very small, we will leave out just 10% of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f53be0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.get_train_val_split(test_size=0.1, stratified=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70fbe2cc",
   "metadata": {},
   "source": [
    "The statistics in the resulting dataset are the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f341c5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  ['Control', 'Left', 'ET', 'Control', 'Right', 'Right', 'ET', 'ET', 'Left', 'Right', 'ET', 'Control', 'Control', 'ET', 'ET', 'ET', 'ET', 'Left', 'Right', 'Left', 'Right', 'Left', 'Left', 'Right', 'Right', 'ET', 'Left', 'Right', 'Control', 'Control', 'Control', 'ET', 'ET', 'Left', 'Right', 'Right']\n",
      "Test: ['Control', 'ET', 'Left', 'Right', 'ET']\n"
     ]
    }
   ],
   "source": [
    "print(f'Train:  {data.y_train}')\n",
    "print(f'Test: {data.y_test}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb866056",
   "metadata": {},
   "source": [
    "Now we can perform the data augmentation for the training data. Test data will be used for test only."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a742b0",
   "metadata": {},
   "source": [
    "## Data augmentation\n",
    "Data augmentation is performed based on patients category such that:\n",
    "\n",
    "Control group can be augmentented withing the control group to get the total number of data:\n",
    "\n",
    "perm = $n_{controlgroup}^{2}$\n",
    "\n",
    "ET group can be augmented withing the ET group to get the total number of data:\n",
    "\n",
    "perm = $n_{ET}^{2}$\n",
    "\n",
    "Finally, Parkinson group for Left and Right Parkinson can be augmented within each other.\n",
    "\n",
    "perm = $(n_{Left}+n_{Right})^{2}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "56a545de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# patients ET, let't get them from training data\n",
    "et_patients = []\n",
    "for i, y in enumerate(data.y_train):\n",
    "    if y== 'ET':\n",
    "        et_patients.append(data.X_train[i])\n",
    "assert len(et_patients) == data.y_train.count('ET')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ad574a81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "Totally, we have 121 ET patients using the augmentation\n"
     ]
    }
   ],
   "source": [
    "# now let's augment these patients\n",
    "ind = get_augmentation_indexes(et_patients)\n",
    "et_augmented = augment_data(et_patients, ind)\n",
    "print(f'Totally, we have {len(et_augmented)} ET patients using the augmentation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6294a5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's do the same for the control group\n",
    "control_patients = []\n",
    "for i, y in enumerate(data.y_train):\n",
    "    if y== 'Control':\n",
    "        control_patients.append(data.X_train[i])\n",
    "assert len(control_patients) == data.y_train.count('Control')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fed74fef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "Totally, we have 49 Control  patients using the augmentation\n"
     ]
    }
   ],
   "source": [
    "# now let's augment these patients\n",
    "ind = get_augmentation_indexes(control_patients)\n",
    "control_augmented = augment_data(control_patients, ind)\n",
    "print(f'Totally, we have {len(control_augmented)} Control  patients using the augmentation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "abd3ab94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, let's proceed to the Parkinson group\n",
    "parkinson_patients = []\n",
    "for i, y in enumerate(data.y_train):\n",
    "    if y== 'Left' or y == 'Right':\n",
    "        parkinson_patients.append(data.X_train[i])\n",
    "assert len(parkinson_patients) == data.y_train.count('Left') + data.y_train.count('Right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2cae5000",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "(4, 65190)\n",
      "Totally, we have 324 Parkinson patients using the augmentation\n"
     ]
    }
   ],
   "source": [
    "# now let's augment these patients\n",
    "ind = get_augmentation_indexes(parkinson_patients)\n",
    "parkinson_augmented = augment_data(parkinson_patients, ind)\n",
    "print(f'Totally, we have {len(parkinson_augmented)} Parkinson patients using the augmentation')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac075f47",
   "metadata": {},
   "source": [
    "## XGBOOST\n",
    "Gradient boosting refers to a class of ensemble machine learning algorithms that can be used for classification or regression predictive modeling problems.\n",
    "\n",
    "Ensembles are constructed from decision tree models. Trees are added one at a time to the ensemble and fit to correct the prediction errors made by prior models. This is a type of ensemble machine learning model referred to as boosting.\n",
    "\n",
    "Extreme Gradient Boosting, or XGBoost for short is an efficient open-source implementation of the gradient boosting algorithm. As such, XGBoost is an algorithm, an open-source project, and a Python library.\n",
    "\n",
    "It was initially developed by Tianqi Chen and was described by Chen and Carlos Guestrin in their 2016 paper titled “XGBoost: A Scalable Tree Boosting System.”\n",
    "\n",
    "[This](https://machinelearningmastery.com/extreme-gradient-boosting-ensemble-in-python/) tutorial was used to apply the XGBoost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f5d733f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80be4389",
   "metadata": {},
   "source": [
    "Let's prepare the dataset for the XGboost tree. \n",
    "Unfortunately, the algorithm  expects the features in the 1D shape. \n",
    "Therefore, first, the data are transformed into 1D vectors.\n",
    "Simple concatination was chosen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "087bbe51",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_patients = len(parkinson_augmented)+len(control_augmented)+len(et_patients)\n",
    "X = np.zeros((total_patients, 65190*4)) # whole dataset\n",
    "for i, patient in enumerate(parkinson_augmented + control_augmented + et_patients):\n",
    "    patient_1d = patient.ravel()\n",
    "    X[i,:] = patient_1d\n",
    "y =  np.array(len(parkinson_augmented)*[0] + len(control_augmented)*[1]+len(et_patients)*[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "23d90bb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(384, 260760)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c482c345",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.974 (0.005)\n"
     ]
    }
   ],
   "source": [
    "# test classification dataset\n",
    "# evaluate xgboost algorithm for classification\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from xgboost import XGBClassifier\n",
    "# define the model\n",
    "model = XGBClassifier()\n",
    "# evaluate the model\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "n_scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "# report performance\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2959881",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
